{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebd0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python detect_mask_video.py\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa56e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to capture the image \n",
    "def detect_and_predict_mask(frame,faceNet,maskNet):\n",
    "    # to get the dimension of the frame and to construct the blob\n",
    "    (h,w)= frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame,1.0,(300,300),\n",
    "                                 (104.0,177.0,123.0))\n",
    "    \n",
    "    #pass the blob through model and detect the face using faceNet\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "    \n",
    "    #initialize the list of face and the corresponding locatins and the list of predicitons from our face mask model\n",
    "    \n",
    "    faces =[]\n",
    "    locs =[]\n",
    "    preds =[]\n",
    "    \n",
    "    # loop over detections\n",
    "    for i in range(0,detections.shape[2]):\n",
    "        # extract the probability\n",
    "        confidence = detections[0,0,i,2]\n",
    "        \n",
    "        #filter out weak detections by ensuring the confidence/probability value\n",
    "        # (i.e) the confidence value is greater than the min conf value\n",
    "        \n",
    "        if confidence>args['confidence']:\n",
    "            #compute the x and y coordinates of bounding box \n",
    "            \n",
    "            box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "            (startX,startY,endX,endY)=box.astype(\"int\")\n",
    "            \n",
    "            #ensure the box falls within the face dim\n",
    "            (startX,startY) =(max(0,startX),max(0,startY))\n",
    "            (endX,endY) = (min(w-1,endX),min(h-1,endY))\n",
    "            face = frame[startY:endY,startX:endX]\n",
    "\n",
    "            # Debugging statements\n",
    "            print(f\"Detection {i}: confidence={confidence}\")\n",
    "            print(f\"Bounding box: startX={startX}, startY={startY}, endX={endX}, endY={endY}\")\n",
    "            print(f\"Face shape: {face.shape}\")\n",
    "\n",
    "            if face.size == 0:\n",
    "                print(\"Empty face image detected, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            #extract the face ROI, convert it to BGR to RGB channel ordering, resize it to 224x224, and preprocess it\n",
    "            # face = frame[startY:endY,startX:endX]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face,(224,224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "            \n",
    "            # add the face and bounding box to the respective list\n",
    "            faces.append(face)\n",
    "            locs.append((startX,startY,endX,endY))\n",
    "            \n",
    "    # to give a condition to predict atleast one face was detected\n",
    "    if len(faces)>0:\n",
    "# for faster inference we'll make batch predictions on *all*\n",
    "# faces at the same time rather than one-by-one predictions\n",
    "# in the above `for` loop\n",
    "        faces = np.array(faces,dtype ='float32')\n",
    "        preds = maskNet.predict(faces,batch_size = 32)\n",
    "        \n",
    "    return (locs,preds)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b513c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototxt path: C:\\HOPE\\Deep Learning\\Face Mask Dectection\\face_detector\\deploy.prototxt\n",
      "Weights path: C:\\HOPE\\Deep Learning\\Face Mask Dectection\\face_detector\\res10_300x300_ssd_iter_140000.caffemodel\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "# Construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-f\", \"--face\", type=str, default=\"face_detector\", help=\"path to face detector model directory\")\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, default=\"mask_detector.h5\", help=\"path to trained face mask detector model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5, help=\"minimum probability to filter weak detections\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# Construct the absolute paths to the model files\n",
    "project_root = os.path.abspath(os.path.dirname(r\"C:\\HOPE\\Deep Learning\\Face Mask Dectection\\face_detector\"))\n",
    "face_detector_directory = os.path.join(project_root, 'face_detector')\n",
    "prototxtPath = os.path.join(face_detector_directory, \"deploy.prototxt\")\n",
    "weightsPath = os.path.join(face_detector_directory, \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "print(f\"Prototxt path: {prototxtPath}\")\n",
    "print(f\"Weights path: {weightsPath}\")\n",
    "\n",
    "if not os.path.exists(prototxtPath):\n",
    "    print(f\"Error: {prototxtPath} not found.\")\n",
    "if not os.path.exists(weightsPath):\n",
    "    print(f\"Error: {weightsPath} not found.\")\n",
    "\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df553c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the face mask detector model from disk\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "maskNet = load_model(args[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e97d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a644e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 0: confidence=0.7875673770904541\n",
      "Bounding box: startX=187, startY=99, endX=298, endY=233\n",
      "Face shape: (134, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.8878187537193298\n",
      "Bounding box: startX=188, startY=94, endX=296, endY=226\n",
      "Face shape: (132, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.8395746350288391\n",
      "Bounding box: startX=186, startY=89, endX=292, endY=226\n",
      "Face shape: (137, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.8253311514854431\n",
      "Bounding box: startX=183, startY=84, endX=293, endY=228\n",
      "Face shape: (144, 110, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9551381468772888\n",
      "Bounding box: startX=183, startY=84, endX=292, endY=225\n",
      "Face shape: (141, 109, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Detection 0: confidence=0.9756070375442505\n",
      "Bounding box: startX=181, startY=79, endX=291, endY=221\n",
      "Face shape: (142, 110, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Detection 0: confidence=0.7873796224594116\n",
      "Bounding box: startX=193, startY=43, endX=304, endY=202\n",
      "Face shape: (159, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.6840617060661316\n",
      "Bounding box: startX=211, startY=3, endX=328, endY=168\n",
      "Face shape: (165, 117, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.5890150666236877\n",
      "Bounding box: startX=219, startY=5, endX=332, endY=159\n",
      "Face shape: (154, 113, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.563806414604187\n",
      "Bounding box: startX=221, startY=7, endX=330, endY=167\n",
      "Face shape: (160, 109, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Detection 0: confidence=0.8584912419319153\n",
      "Bounding box: startX=220, startY=14, endX=327, endY=171\n",
      "Face shape: (157, 107, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.6763102412223816\n",
      "Bounding box: startX=220, startY=29, endX=323, endY=179\n",
      "Face shape: (150, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Detection 0: confidence=0.5647197365760803\n",
      "Bounding box: startX=222, startY=31, endX=326, endY=180\n",
      "Face shape: (149, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9141338467597961\n",
      "Bounding box: startX=223, startY=36, endX=327, endY=189\n",
      "Face shape: (153, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.8063988089561462\n",
      "Bounding box: startX=225, startY=39, endX=329, endY=192\n",
      "Face shape: (153, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Detection 0: confidence=0.7630549669265747\n",
      "Bounding box: startX=227, startY=49, endX=326, endY=193\n",
      "Face shape: (144, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.8283298015594482\n",
      "Bounding box: startX=226, startY=53, endX=325, endY=192\n",
      "Face shape: (139, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Detection 0: confidence=0.7562788128852844\n",
      "Bounding box: startX=220, startY=50, endX=322, endY=193\n",
      "Face shape: (143, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9329678416252136\n",
      "Bounding box: startX=218, startY=50, endX=317, endY=196\n",
      "Face shape: (146, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.7579311728477478\n",
      "Bounding box: startX=218, startY=48, endX=317, endY=196\n",
      "Face shape: (148, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Detection 0: confidence=0.8183462619781494\n",
      "Bounding box: startX=215, startY=49, endX=317, endY=198\n",
      "Face shape: (149, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.8040165901184082\n",
      "Bounding box: startX=214, startY=49, endX=313, endY=196\n",
      "Face shape: (147, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.8350837230682373\n",
      "Bounding box: startX=213, startY=49, endX=312, endY=195\n",
      "Face shape: (146, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.8447525501251221\n",
      "Bounding box: startX=214, startY=48, endX=314, endY=194\n",
      "Face shape: (146, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.7373462319374084\n",
      "Bounding box: startX=214, startY=48, endX=312, endY=194\n",
      "Face shape: (146, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.6842740774154663\n",
      "Bounding box: startX=214, startY=50, endX=311, endY=194\n",
      "Face shape: (144, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Detection 0: confidence=0.5809269547462463\n",
      "Bounding box: startX=212, startY=50, endX=311, endY=195\n",
      "Face shape: (145, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.5464510917663574\n",
      "Bounding box: startX=211, startY=50, endX=310, endY=197\n",
      "Face shape: (147, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.5859305262565613\n",
      "Bounding box: startX=211, startY=51, endX=308, endY=197\n",
      "Face shape: (146, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.6451840400695801\n",
      "Bounding box: startX=211, startY=50, endX=309, endY=197\n",
      "Face shape: (147, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.6493502855300903\n",
      "Bounding box: startX=211, startY=50, endX=309, endY=198\n",
      "Face shape: (148, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.6885194182395935\n",
      "Bounding box: startX=211, startY=53, endX=309, endY=199\n",
      "Face shape: (146, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.6088173985481262\n",
      "Bounding box: startX=210, startY=50, endX=307, endY=195\n",
      "Face shape: (145, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Detection 0: confidence=0.5254332423210144\n",
      "Bounding box: startX=204, startY=52, endX=303, endY=193\n",
      "Face shape: (141, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.5618419051170349\n",
      "Bounding box: startX=204, startY=52, endX=303, endY=193\n",
      "Face shape: (141, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.5694959759712219\n",
      "Bounding box: startX=203, startY=53, endX=302, endY=193\n",
      "Face shape: (140, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.5071282982826233\n",
      "Bounding box: startX=204, startY=52, endX=303, endY=196\n",
      "Face shape: (144, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.5426092147827148\n",
      "Bounding box: startX=204, startY=53, endX=302, endY=194\n",
      "Face shape: (141, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.620293378829956\n",
      "Bounding box: startX=201, startY=56, endX=299, endY=194\n",
      "Face shape: (138, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.5313559770584106\n",
      "Bounding box: startX=208, startY=57, endX=309, endY=198\n",
      "Face shape: (141, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.5796631574630737\n",
      "Bounding box: startX=198, startY=56, endX=300, endY=195\n",
      "Face shape: (139, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.7468499541282654\n",
      "Bounding box: startX=198, startY=57, endX=303, endY=195\n",
      "Face shape: (138, 105, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.5460401773452759\n",
      "Bounding box: startX=201, startY=52, endX=305, endY=196\n",
      "Face shape: (144, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.5104081630706787\n",
      "Bounding box: startX=203, startY=53, endX=305, endY=194\n",
      "Face shape: (141, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.6517587304115295\n",
      "Bounding box: startX=204, startY=49, endX=305, endY=192\n",
      "Face shape: (143, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.7252952456474304\n",
      "Bounding box: startX=208, startY=52, endX=306, endY=196\n",
      "Face shape: (144, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.6277663111686707\n",
      "Bounding box: startX=207, startY=53, endX=307, endY=194\n",
      "Face shape: (141, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.7421972155570984\n",
      "Bounding box: startX=208, startY=53, endX=307, endY=195\n",
      "Face shape: (142, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.6073412895202637\n",
      "Bounding box: startX=208, startY=56, endX=308, endY=195\n",
      "Face shape: (139, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.7668395638465881\n",
      "Bounding box: startX=209, startY=56, endX=308, endY=194\n",
      "Face shape: (138, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.8555986285209656\n",
      "Bounding box: startX=215, startY=56, endX=311, endY=190\n",
      "Face shape: (134, 96, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9515430927276611\n",
      "Bounding box: startX=219, startY=48, endX=317, endY=188\n",
      "Face shape: (140, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.942025899887085\n",
      "Bounding box: startX=219, startY=44, endX=320, endY=187\n",
      "Face shape: (143, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9532691240310669\n",
      "Bounding box: startX=217, startY=42, endX=318, endY=186\n",
      "Face shape: (144, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9567670226097107\n",
      "Bounding box: startX=216, startY=43, endX=314, endY=189\n",
      "Face shape: (146, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9504151344299316\n",
      "Bounding box: startX=216, startY=43, endX=315, endY=187\n",
      "Face shape: (144, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9479115009307861\n",
      "Bounding box: startX=215, startY=43, endX=314, endY=190\n",
      "Face shape: (147, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9428562521934509\n",
      "Bounding box: startX=214, startY=43, endX=312, endY=185\n",
      "Face shape: (142, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Detection 0: confidence=0.8029743432998657\n",
      "Bounding box: startX=213, startY=44, endX=312, endY=188\n",
      "Face shape: (144, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9130083918571472\n",
      "Bounding box: startX=211, startY=46, endX=311, endY=190\n",
      "Face shape: (144, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.8436009883880615\n",
      "Bounding box: startX=210, startY=46, endX=309, endY=189\n",
      "Face shape: (143, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Detection 0: confidence=0.887811541557312\n",
      "Bounding box: startX=209, startY=45, endX=309, endY=189\n",
      "Face shape: (144, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.8730903267860413\n",
      "Bounding box: startX=209, startY=46, endX=310, endY=190\n",
      "Face shape: (144, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Detection 0: confidence=0.8352716565132141\n",
      "Bounding box: startX=210, startY=46, endX=308, endY=191\n",
      "Face shape: (145, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.8060787320137024\n",
      "Bounding box: startX=210, startY=46, endX=309, endY=193\n",
      "Face shape: (147, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.8198879361152649\n",
      "Bounding box: startX=211, startY=47, endX=309, endY=194\n",
      "Face shape: (147, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Detection 0: confidence=0.8682011365890503\n",
      "Bounding box: startX=211, startY=48, endX=310, endY=193\n",
      "Face shape: (145, 99, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Detection 0: confidence=0.7783997654914856\n",
      "Bounding box: startX=208, startY=52, endX=309, endY=194\n",
      "Face shape: (142, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Detection 0: confidence=0.6731857061386108\n",
      "Bounding box: startX=208, startY=52, endX=309, endY=195\n",
      "Face shape: (143, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.7455975413322449\n",
      "Bounding box: startX=209, startY=52, endX=310, endY=194\n",
      "Face shape: (142, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.7317888736724854\n",
      "Bounding box: startX=209, startY=50, endX=310, endY=196\n",
      "Face shape: (146, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.700175404548645\n",
      "Bounding box: startX=212, startY=47, endX=312, endY=193\n",
      "Face shape: (146, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.8926340341567993\n",
      "Bounding box: startX=216, startY=38, endX=318, endY=187\n",
      "Face shape: (149, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9398034811019897\n",
      "Bounding box: startX=217, startY=35, endX=321, endY=181\n",
      "Face shape: (146, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.9239041209220886\n",
      "Bounding box: startX=217, startY=36, endX=323, endY=182\n",
      "Face shape: (146, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Detection 0: confidence=0.9929946064949036\n",
      "Bounding box: startX=220, startY=35, endX=326, endY=184\n",
      "Face shape: (149, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9853323101997375\n",
      "Bounding box: startX=220, startY=35, endX=326, endY=186\n",
      "Face shape: (151, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9895728230476379\n",
      "Bounding box: startX=221, startY=36, endX=327, endY=185\n",
      "Face shape: (149, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.8292299509048462\n",
      "Bounding box: startX=223, startY=36, endX=327, endY=184\n",
      "Face shape: (148, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.9304428696632385\n",
      "Bounding box: startX=223, startY=34, endX=329, endY=186\n",
      "Face shape: (152, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9829965233802795\n",
      "Bounding box: startX=223, startY=36, endX=329, endY=188\n",
      "Face shape: (152, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9712281227111816\n",
      "Bounding box: startX=222, startY=36, endX=327, endY=188\n",
      "Face shape: (152, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9734141826629639\n",
      "Bounding box: startX=222, startY=37, endX=326, endY=186\n",
      "Face shape: (149, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9625846147537231\n",
      "Bounding box: startX=220, startY=37, endX=325, endY=188\n",
      "Face shape: (151, 105, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.970615804195404\n",
      "Bounding box: startX=217, startY=44, endX=320, endY=193\n",
      "Face shape: (149, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.8615137934684753\n",
      "Bounding box: startX=213, startY=61, endX=311, endY=203\n",
      "Face shape: (142, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.8689196705818176\n",
      "Bounding box: startX=211, startY=72, endX=308, endY=210\n",
      "Face shape: (138, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.746982753276825\n",
      "Bounding box: startX=210, startY=69, endX=308, endY=209\n",
      "Face shape: (140, 98, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.925187885761261\n",
      "Bounding box: startX=198, startY=74, endX=306, endY=207\n",
      "Face shape: (133, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.843978762626648\n",
      "Bounding box: startX=204, startY=76, endX=310, endY=209\n",
      "Face shape: (133, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9763579964637756\n",
      "Bounding box: startX=205, startY=75, endX=310, endY=220\n",
      "Face shape: (145, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9866721630096436\n",
      "Bounding box: startX=210, startY=67, endX=313, endY=227\n",
      "Face shape: (160, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9976056814193726\n",
      "Bounding box: startX=211, startY=57, endX=316, endY=201\n",
      "Face shape: (144, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.999825656414032\n",
      "Bounding box: startX=212, startY=47, endX=319, endY=199\n",
      "Face shape: (152, 107, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9998407363891602\n",
      "Bounding box: startX=212, startY=48, endX=321, endY=202\n",
      "Face shape: (154, 109, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9999040365219116\n",
      "Bounding box: startX=212, startY=52, endX=322, endY=208\n",
      "Face shape: (156, 110, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9999351501464844\n",
      "Bounding box: startX=212, startY=53, endX=323, endY=207\n",
      "Face shape: (154, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9999363422393799\n",
      "Bounding box: startX=214, startY=50, endX=326, endY=207\n",
      "Face shape: (157, 112, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9999346733093262\n",
      "Bounding box: startX=216, startY=47, endX=326, endY=203\n",
      "Face shape: (156, 110, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9999260902404785\n",
      "Bounding box: startX=216, startY=47, endX=326, endY=203\n",
      "Face shape: (156, 110, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9999533891677856\n",
      "Bounding box: startX=215, startY=48, endX=326, endY=202\n",
      "Face shape: (154, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9999274015426636\n",
      "Bounding box: startX=214, startY=49, endX=326, endY=206\n",
      "Face shape: (157, 112, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9999219179153442\n",
      "Bounding box: startX=215, startY=49, endX=325, endY=203\n",
      "Face shape: (154, 110, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9999070167541504\n",
      "Bounding box: startX=215, startY=48, endX=326, endY=202\n",
      "Face shape: (154, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9998986721038818\n",
      "Bounding box: startX=214, startY=48, endX=325, endY=207\n",
      "Face shape: (159, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9999293088912964\n",
      "Bounding box: startX=214, startY=50, endX=325, endY=207\n",
      "Face shape: (157, 111, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9999383687973022\n",
      "Bounding box: startX=215, startY=51, endX=323, endY=206\n",
      "Face shape: (155, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9998160004615784\n",
      "Bounding box: startX=214, startY=52, endX=321, endY=199\n",
      "Face shape: (147, 107, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9989469647407532\n",
      "Bounding box: startX=212, startY=53, endX=318, endY=199\n",
      "Face shape: (146, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9235560894012451\n",
      "Bounding box: startX=206, startY=58, endX=314, endY=218\n",
      "Face shape: (160, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.8784652352333069\n",
      "Bounding box: startX=209, startY=61, endX=310, endY=203\n",
      "Face shape: (142, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.840327262878418\n",
      "Bounding box: startX=210, startY=60, endX=312, endY=198\n",
      "Face shape: (138, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.6134516000747681\n",
      "Bounding box: startX=213, startY=61, endX=313, endY=212\n",
      "Face shape: (151, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.7439080476760864\n",
      "Bounding box: startX=212, startY=58, endX=309, endY=196\n",
      "Face shape: (138, 97, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9659515023231506\n",
      "Bounding box: startX=216, startY=57, endX=317, endY=197\n",
      "Face shape: (140, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9611082077026367\n",
      "Bounding box: startX=216, startY=55, endX=318, endY=197\n",
      "Face shape: (142, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9070577621459961\n",
      "Bounding box: startX=216, startY=56, endX=316, endY=197\n",
      "Face shape: (141, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9677243232727051\n",
      "Bounding box: startX=218, startY=59, endX=318, endY=198\n",
      "Face shape: (139, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9402857422828674\n",
      "Bounding box: startX=220, startY=54, endX=320, endY=202\n",
      "Face shape: (148, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9102832674980164\n",
      "Bounding box: startX=226, startY=55, endX=328, endY=202\n",
      "Face shape: (147, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9032595753669739\n",
      "Bounding box: startX=226, startY=53, endX=327, endY=195\n",
      "Face shape: (142, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9658042788505554\n",
      "Bounding box: startX=218, startY=53, endX=318, endY=198\n",
      "Face shape: (145, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9930756092071533\n",
      "Bounding box: startX=212, startY=48, endX=314, endY=194\n",
      "Face shape: (146, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9879934787750244\n",
      "Bounding box: startX=202, startY=45, endX=306, endY=189\n",
      "Face shape: (144, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9997521042823792\n",
      "Bounding box: startX=195, startY=42, endX=301, endY=183\n",
      "Face shape: (141, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.9998561143875122\n",
      "Bounding box: startX=191, startY=41, endX=300, endY=179\n",
      "Face shape: (138, 109, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9998923540115356\n",
      "Bounding box: startX=191, startY=42, endX=300, endY=180\n",
      "Face shape: (138, 109, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9991509914398193\n",
      "Bounding box: startX=196, startY=40, endX=304, endY=179\n",
      "Face shape: (139, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9961723685264587\n",
      "Bounding box: startX=205, startY=47, endX=311, endY=186\n",
      "Face shape: (139, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.9992930889129639\n",
      "Bounding box: startX=209, startY=47, endX=314, endY=188\n",
      "Face shape: (141, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9998465776443481\n",
      "Bounding box: startX=213, startY=50, endX=317, endY=188\n",
      "Face shape: (138, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9999315738677979\n",
      "Bounding box: startX=214, startY=49, endX=320, endY=188\n",
      "Face shape: (139, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9999504089355469\n",
      "Bounding box: startX=216, startY=50, endX=321, endY=189\n",
      "Face shape: (139, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9999346733093262\n",
      "Bounding box: startX=216, startY=51, endX=321, endY=189\n",
      "Face shape: (138, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Detection 0: confidence=0.9999254941940308\n",
      "Bounding box: startX=216, startY=51, endX=319, endY=189\n",
      "Face shape: (138, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Detection 0: confidence=0.9998681545257568\n",
      "Bounding box: startX=215, startY=51, endX=318, endY=189\n",
      "Face shape: (138, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9998483657836914\n",
      "Bounding box: startX=215, startY=51, endX=317, endY=189\n",
      "Face shape: (138, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9996472597122192\n",
      "Bounding box: startX=213, startY=51, endX=316, endY=189\n",
      "Face shape: (138, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9986159801483154\n",
      "Bounding box: startX=211, startY=52, endX=312, endY=190\n",
      "Face shape: (138, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Detection 0: confidence=0.9646369218826294\n",
      "Bounding box: startX=205, startY=51, endX=307, endY=192\n",
      "Face shape: (141, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Detection 0: confidence=0.9871254563331604\n",
      "Bounding box: startX=202, startY=50, endX=303, endY=188\n",
      "Face shape: (138, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Detection 0: confidence=0.99241042137146\n",
      "Bounding box: startX=201, startY=51, endX=304, endY=188\n",
      "Face shape: (137, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9962357878684998\n",
      "Bounding box: startX=200, startY=51, endX=303, endY=189\n",
      "Face shape: (138, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9953095316886902\n",
      "Bounding box: startX=200, startY=50, endX=303, endY=190\n",
      "Face shape: (140, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9968515038490295\n",
      "Bounding box: startX=199, startY=51, endX=303, endY=190\n",
      "Face shape: (139, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.997156023979187\n",
      "Bounding box: startX=199, startY=51, endX=302, endY=189\n",
      "Face shape: (138, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9979281425476074\n",
      "Bounding box: startX=199, startY=49, endX=302, endY=189\n",
      "Face shape: (140, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Detection 0: confidence=0.9992665648460388\n",
      "Bounding box: startX=198, startY=47, endX=300, endY=187\n",
      "Face shape: (140, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9995933175086975\n",
      "Bounding box: startX=197, startY=47, endX=299, endY=187\n",
      "Face shape: (140, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Detection 0: confidence=0.9996254444122314\n",
      "Bounding box: startX=196, startY=49, endX=298, endY=188\n",
      "Face shape: (139, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Detection 0: confidence=0.9995872378349304\n",
      "Bounding box: startX=196, startY=49, endX=298, endY=188\n",
      "Face shape: (139, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9996719360351562\n",
      "Bounding box: startX=195, startY=49, endX=298, endY=188\n",
      "Face shape: (139, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9996838569641113\n",
      "Bounding box: startX=195, startY=49, endX=298, endY=190\n",
      "Face shape: (141, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Detection 0: confidence=0.9994383454322815\n",
      "Bounding box: startX=195, startY=52, endX=297, endY=190\n",
      "Face shape: (138, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9993368983268738\n",
      "Bounding box: startX=195, startY=53, endX=298, endY=190\n",
      "Face shape: (137, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9993709921836853\n",
      "Bounding box: startX=195, startY=53, endX=297, endY=190\n",
      "Face shape: (137, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9993053674697876\n",
      "Bounding box: startX=195, startY=54, endX=298, endY=190\n",
      "Face shape: (136, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Detection 0: confidence=0.9993950128555298\n",
      "Bounding box: startX=195, startY=54, endX=297, endY=190\n",
      "Face shape: (136, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9994187355041504\n",
      "Bounding box: startX=195, startY=54, endX=298, endY=190\n",
      "Face shape: (136, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9992330074310303\n",
      "Bounding box: startX=195, startY=55, endX=297, endY=191\n",
      "Face shape: (136, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9992679953575134\n",
      "Bounding box: startX=195, startY=55, endX=297, endY=190\n",
      "Face shape: (135, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9993159770965576\n",
      "Bounding box: startX=195, startY=55, endX=297, endY=190\n",
      "Face shape: (135, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9993195533752441\n",
      "Bounding box: startX=195, startY=55, endX=297, endY=191\n",
      "Face shape: (136, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.999164342880249\n",
      "Bounding box: startX=196, startY=55, endX=297, endY=192\n",
      "Face shape: (137, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9992863535881042\n",
      "Bounding box: startX=196, startY=54, endX=297, endY=192\n",
      "Face shape: (138, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9993460774421692\n",
      "Bounding box: startX=195, startY=55, endX=297, endY=192\n",
      "Face shape: (137, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9994215965270996\n",
      "Bounding box: startX=196, startY=54, endX=296, endY=192\n",
      "Face shape: (138, 100, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9993315935134888\n",
      "Bounding box: startX=195, startY=54, endX=298, endY=191\n",
      "Face shape: (137, 103, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9986880421638489\n",
      "Bounding box: startX=196, startY=56, endX=298, endY=193\n",
      "Face shape: (137, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9983413219451904\n",
      "Bounding box: startX=197, startY=55, endX=299, endY=193\n",
      "Face shape: (138, 102, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9969635605812073\n",
      "Bounding box: startX=198, startY=55, endX=301, endY=194\n",
      "Face shape: (139, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Detection 0: confidence=0.9968781471252441\n",
      "Bounding box: startX=197, startY=58, endX=301, endY=198\n",
      "Face shape: (140, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9958882927894592\n",
      "Bounding box: startX=198, startY=58, endX=301, endY=196\n",
      "Face shape: (138, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Detection 0: confidence=0.9944936037063599\n",
      "Bounding box: startX=199, startY=60, endX=302, endY=197\n",
      "Face shape: (137, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Detection 0: confidence=0.9892927408218384\n",
      "Bounding box: startX=201, startY=59, endX=302, endY=200\n",
      "Face shape: (141, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9852367043495178\n",
      "Bounding box: startX=201, startY=59, endX=302, endY=199\n",
      "Face shape: (140, 101, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9730236530303955\n",
      "Bounding box: startX=207, startY=57, endX=310, endY=198\n",
      "Face shape: (141, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9998010993003845\n",
      "Bounding box: startX=213, startY=56, endX=320, endY=197\n",
      "Face shape: (141, 107, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Detection 0: confidence=0.9999864101409912\n",
      "Bounding box: startX=220, startY=55, endX=326, endY=196\n",
      "Face shape: (141, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Detection 0: confidence=0.9999904632568359\n",
      "Bounding box: startX=228, startY=54, endX=336, endY=202\n",
      "Face shape: (148, 108, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Detection 0: confidence=0.9999973773956299\n",
      "Bounding box: startX=223, startY=58, endX=332, endY=204\n",
      "Face shape: (146, 109, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Detection 0: confidence=0.9999914169311523\n",
      "Bounding box: startX=217, startY=59, endX=323, endY=203\n",
      "Face shape: (144, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9998553991317749\n",
      "Bounding box: startX=213, startY=58, endX=317, endY=202\n",
      "Face shape: (144, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9978247880935669\n",
      "Bounding box: startX=209, startY=58, endX=313, endY=202\n",
      "Face shape: (144, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Detection 0: confidence=0.993768572807312\n",
      "Bounding box: startX=207, startY=58, endX=312, endY=201\n",
      "Face shape: (143, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Detection 0: confidence=0.9893432855606079\n",
      "Bounding box: startX=206, startY=58, endX=312, endY=201\n",
      "Face shape: (143, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Detection 0: confidence=0.9770723581314087\n",
      "Bounding box: startX=206, startY=58, endX=311, endY=199\n",
      "Face shape: (141, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Detection 0: confidence=0.9742367267608643\n",
      "Bounding box: startX=205, startY=57, endX=310, endY=200\n",
      "Face shape: (143, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Detection 0: confidence=0.9833537340164185\n",
      "Bounding box: startX=207, startY=58, endX=311, endY=200\n",
      "Face shape: (142, 104, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Detection 0: confidence=0.9892655611038208\n",
      "Bounding box: startX=207, startY=58, endX=312, endY=199\n",
      "Face shape: (141, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Detection 0: confidence=0.9956504702568054\n",
      "Bounding box: startX=208, startY=58, endX=313, endY=200\n",
      "Face shape: (142, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Detection 0: confidence=0.9969186782836914\n",
      "Bounding box: startX=209, startY=58, endX=312, endY=201\n",
      "Face shape: (143, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Detection 0: confidence=0.9976468682289124\n",
      "Bounding box: startX=210, startY=59, endX=313, endY=201\n",
      "Face shape: (142, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.999403715133667\n",
      "Bounding box: startX=210, startY=59, endX=316, endY=201\n",
      "Face shape: (142, 106, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Detection 0: confidence=0.9995562434196472\n",
      "Bounding box: startX=211, startY=60, endX=316, endY=202\n",
      "Face shape: (142, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Detection 0: confidence=0.999845027923584\n",
      "Bounding box: startX=211, startY=61, endX=316, endY=203\n",
      "Face shape: (142, 105, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Detection 0: confidence=0.9993384480476379\n",
      "Bounding box: startX=211, startY=60, endX=314, endY=202\n",
      "Face shape: (142, 103, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebcamVideoStream' object has no attribute 'release'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# do a bit of cleanup\u001b[39;00m\n\u001b[0;32m     48\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 50\u001b[0m vs\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebcamVideoStream' object has no attribute 'release'"
     ]
    }
   ],
   "source": [
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # detect faces in the frame and determine if they are wearing a\n",
    "    # face mask or not\n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "    # loop over the detected face locations and their corresponding\n",
    "    # locations\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        # unpack the bounding box and predictions\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        # determine the class label and color we'll use to draw\n",
    "        # the bounding box and text\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "        # include the probability in the label\n",
    "        #label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "        \n",
    "        # display the label and bounding box rectangle on the output\n",
    "        # frame\n",
    "        if(label==\"Mask\"):    \n",
    "            cv2.putText(frame,\"Mask: You are allowed\", (startX, startY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "        elif(label==\"No Mask\"):\n",
    "            lab=\"No Mask: You are not allowed\"\n",
    "            cv2.putText(frame, lab, (startX, startY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
